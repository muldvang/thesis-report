% chktex-file 44

\chapter{Conclusion}
\label{cha:conclusion}

\citet{sand2013ziphmmlib} implements a zipHMM for working
with hidden Markov models. It includes an efficient implementation of the forward
algorithm that obtains a speedup compared to the classical implementation by
exploiting repetitions in the input sequence.

In this master's thesis the zipHMM library has been extended to include
implementations of the Viterbi, the backward and two variants of the posterior
decoding algorithms. This includes description of the theory behind the
algorithm, efficient implementations of these, and experiments that evaluates
the performance compared to the standard implementation.

By exploiting repetitions in the observation sequence the running time of the
Viterbi algorithm has changed from $O(N^2 T)$, with $N$ being the number of
states and $T$ being the length of the observation sequence, to $O(N^2 T')$
where $T'$ is the length of the compression observation sequence for computing
the probability of the most likely path and $O(N^2 T' + T)$ for also getting
the path. This requires that the observation sequence has been preprocessed.
This takes time $O(M' N^3)$ with $M'$ being the new alphabet size that is
dependent on the data and a user provided estimate of how many times the
Viterbi algorithm is executed afterwards.

The experiments show that a possibly very large speedup can be gained. However,
it is very dependent on how well the data compresses, i.e.\ how many repetitions
the observation sequence contains, and how many times the user estimates that the
algorithm is executed after the compression. Furthermore, since the
preprocessing is cubic in the number of states, a speedup is not obtained for
large models.

The backward algorithm has been implemented as part of the implementation for
computing the posterior decoding. It has not been possible to find a method for
exploiting repetitions in the observation sequence, so in practice it becomes a
battle between constants whether the classical version or the zipHMMlib version
is the fastest. In the experimental setup used in this thesis the constants are
in favor of the zipHMMlib implementation, when the observation sequence length and
model size is large enough.

Exploiting repetitions is however possible for posterior decoding if only a
part of the posterior decoding is requested. In that case the running time
becomes $O(M' N^3 + N^2 T' + N^2 (j - i + \log T))$ with $j - i$ being the
length of the requested substring.

\section{Future Work}

zipHMM can be extended beyond what has been implemented in this thesis.

\begin{itemize}
\item In zipHMM a parallelized version of the forward algorithm is implemented.
  This idea is to parallelize equation~\eqref{eq:3} as the max-times
  multiplication can be computed in any order. One processesor computes
  equation~\eqref{eq:3} from right to left while the remaining processors
  computes blocks of the equation from left to right. The first processor will
  compute matrix-vector multiplication while the remaining processors will
  compute matrix-matrix multiplications. Hence, this parallelization scheme
  will work best for small models. Note that $\delta_t$ is not computed for all
  $t \in [1, T]$, since only the first processor makes matrix-vector
  multiplications. Hence, backtracking becomes harder. One solution to this is
  given in \citet{sand2014engineering}, where the missing $\delta_t$ vectors
  are computed and then the path is backtracked. Another idea is to compute
  extra $R$ matrices for each of the matrix-matrix computations. When the
  subset of the $\delta_t$ matrices and the path corresponding to these have
  been computed, the ones missing can be found using the extra $R$ matrices
  using the same technique as in section~\ref{sec:backtracking}.
\item At the current state zipHMM compresses the sequences using a single
  compression stopping criterion as discussed in
  section~\ref{sec:compr-stopp-crit}. Since a BLAS framework is used for the
  implementation of the forward and backward algorithms and a naive max-times
  matrix multiplication is used for Viterbi multiple compression criterions
  could be used. Also, the criterion could depend on whether the Viterbi path
  is request or not. One solution is to compute multiple compressed sequences
  from a single sequence such that the best compression is used for any algorithm.
\item Also save the decompressed sequence along the compressed sequence to
  avoid having to decompress. (This should only give a minor speedup.) \fxwarning{Elaborate.}
\item Implement more efficient matrix computation for Viterbi or store two
  copies in memory with different memory alignments. \fxwarning{Elaborate.}
\item Implement multiple substring requests without having to recompute the
  tables of the compressed sequence. \fxwarning{Elaborate.}
\item Implement substring Viterbi. \fxwarning{Elaborate.}
\item Make bindings for R and Python. \fxwarning{Elaborate.}
\end{itemize}

\fxwarning{Perspective. E.g.\ this changes the way we work with HMMs (or something).}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master.tex"
%%% TeX-command-extra-options: "-shell-escape"
%%% End:
