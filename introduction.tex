% chktex-file 44
\chapter{Introduction}

Hidden Markov models are statistical models that during many years have proven
to be useful in many areas such as speech recognition, optical recognition such
as character recognition and face recognition, and various areas of
bioinformatics, where it has been used for e.g.\ gene finding, modeling protein
structures and sequence alignment. Examples of this can be found in
\citet{rabiner1989tutorial}, \citet{agazzi1993hidden},
\citet{nefian1998hidden}, \citet{burge1997prediction}, and
\citet{eddy1998profile}.

In general, hidden Markov models are efficient and can be used for large data
sets in e.g.\ genome wide analysis, but the running time of the analysis is
still measured in hours or days. Since the introduction of next generation
sequencing has been introduced the amount of available biological data has
increased tremendously, and making faster algorithms for hidden Markov models
is thus of great value.

As the amount of biological data has
rapidly increased since the introduction of next generation sequencing, faster
algorithms for making the hidden Markov models analysis is important.

\citet{lifshits2009speeding} and \citet{sand2013ziphmmlib} use compression of
the input data and minor changes in the algorithms to speedup the
analysis. While \citet{lifshits2009speeding} mainly analyze their method
theoretically, \citet{sand2013ziphmmlib} experimentally proves that the method
has a great potential for analyses using the forward algorithm.

The goal of this thesis is to complent the work made by \citet{sand2013ziphmmlib}
by extending the theory and implementation to include the Viterbi and posterior decoding
algorithms and by making experiments validating the performance of the method
and the implementations.

\section{Outline}

The thesis is structured as follows.

\begin{description}
\item[Chapter~\ref{cha:background}] provides an overview of the work made by
  \citet{lifshits2009speeding} and \citet{sand2013ziphmmlib} and the difference
  between these.
\item[Chapter~\ref{cha:method}] contains theory of the classical formulations
  of the Viterbi and posterior decoding algorithms along with theoretical
  descriptions and analyses of these algorithms using compression.
\item[Chapter~\ref{cha:implementation}] gives an overview of the implementation
  and instructions on how to use the library.
\item[Chapter~\ref{cha:experiments}] checks that the implementation of the
  algorithms fit the theoretical running time and shows the performance gain
  obtained from the compression.
\item[Chapter~\ref{cha:conclusion}] provides an overview of the developed
  theory, the experiments and the results of these. Ideas on how to
  make the framework better are also given.
\end{description}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% End:
