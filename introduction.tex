% chktex-file 44
\chapter{Introduction}

Hidden Markov models are statistical models that during many years have proven
to be useful in many areas such as speech recognition
\citep{rabiner1989tutorial}, optical recognition such as character recognition
\citep{agazzi1993hidden} and face recognition \citep{nefian1998hidden}, and
various areas of bioinformatics, where it has been used for e.g.\ gene finding
\citep{burge1997prediction}, modeling protein structures and sequence alignment
\citep{eddy1998profile}.

In general, hidden Markov models are efficient and may be used for large data
sets in e.g.\ genome wide analysis, but the running time of the analysis may
still be measured in hours or days. As the amount of biological data has
rapidly increased since the introduction of next generation sequencing, faster
algorithms for making the hidden Markov models analysis is important.

\citet{lifshits2009speeding} and \citet{sand2013ziphmmlib} use compression of
the input data and minor changes in the algorithms to speedup the
analysis. While \citet{lifshits2009speeding} mainly analyze their method
theoretically, \citet{sand2013ziphmmlib} experimentally proves that the method
has a great potential for analysis using the forward algorithm.

The goal of this thesis is to extend the work made by \citet{sand2013ziphmmlib}
by adding theory and implementation of the Viterbi and posterior decoding
algorithms and by making experiments validating the performance of the method
and the implementations.

\section{Outline}

The thesis is structured as follows.

\begin{description}
\item[Chapter~\ref{cha:background}] In this short chapter an overview of
  the work made by \citet{lifshits2009speeding} and \citet{sand2013ziphmmlib}
  and the difference between these.
\item[Chapter~\ref{cha:method}] Theoretical descriptions of the Viterbi and
  posterior decoding algorithms are given in this chapter after having
  described the compression used in \citet{sand2013ziphmmlib}.
\item[Chapter~\ref{cha:implementation}] This is a short chapter providing an
  overview and some details of the implementation.
\item[Chapter~\ref{cha:experiments}] The implemented algorithms are compared to
  the theoretical asymptotic running times to ensure that the implementation
  is consistent with the theory.
\item[Chapter~\ref{cha:conclusion}] In the end a conclusion of the theory and
  the results of the experiments in the thesis is made. Some ideas on how to
  make the framework better is also given.
\end{description}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% End:
